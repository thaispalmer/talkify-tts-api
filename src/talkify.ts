import axios, { AxiosError, AxiosResponse, AxiosInstance } from 'axios';
import { Readable } from 'stream';
import TalkifyError from './talkifyError';

/**
 * Default options for the {@link Talkify} class.
 */
export interface TalkifyOptions {
  /**
   * A string that contains the API Key from Talkify, which can be created at [https://manage.talkify.net](https://manage.talkify.net).
   */
  key: string | undefined;

  /**
   * This will determine the output format generated by the Talkify service. Acceptable values: `mp3` and `wav`.
   * @defaultValue `mp3`
   */
  format?: 'mp3' | 'wav';

  /**
   * The language to fallback to Talkify when the service is unable to detect the language automatically. It accepts a string with the language name or a {@link Language} object.
   */
  fallbackLanguage?: Language | string;

  /**
   * The voice to be used when synthetizing text. It accepts a string with the voice name, or a {@link Voice} object. Omit for automatic language detection.
   */
  voice?: Voice | string;

  /**
   * The rate of speech as an signed integer. Accepted range: `-5` to `5`.
   * @defaultValue `0`
   */
  rate?: number;

  /**
   * Defines if the text should be parsed as [SSML](https://en.wikipedia.org/wiki/Speech_Synthesis_Markup_Language) (`true`) or plain text (`false`).
   * @defaultValue `true`
   */
  ssml?: boolean;

  /**
   * Use the whispering effect. Only applicable to [selected voices](https://talkify.net/products/text-to-speech-voices).
   * @defaultValue `false`
   */
  whisper?: boolean;

  /**
   * Use the softer speech effect. Only applicable to [selected voices](https://talkify.net/products/text-to-speech-voices).
   * @defaultValue `false`
   */
  soft?: boolean;

  /**
   * Adjusts the base volume. Only applicable to [selected voices](https://talkify.net/products/text-to-speech-voices). Accepted range: `-10` to `10`.
   * @defaultValue `0`
   */
  volume?: number;

  /**
   * Adds a break in milliseconds between words. Only applicable to [selected voices](https://talkify.net/products/text-to-speech-voices). Accepted range: `0` to `1000`.
   * @defaultValue `0`
   */
  wordBreak?: number;

  /**
   * Controls the pitch of the spoken text. Accepted range: `-10` to `10`.
   * @defaultValue `0`
   */
  pitch?: number;
}

/**
 * Options for the {@link Talkify.speech} method.
 */
export type SpeechOptions = Omit<TalkifyOptions, 'key'>;

/**
 * The generated speech as a [`Readable` stream](https://nodejs.org/api/stream.html#readable-streams).
 */
export type SpeechStream = AxiosResponse<Readable>['data'];

/**
 * A voice that can be used for speech synthesis. This object contains its metadata and available features.
 */
export type Voice = {
  /**
   * The language culture string.
   * Example: `en-US`.
   */
  culture: string;

  /**
   * Name of the voice, this is used for the `voice` parameter when calling the {@link Talkify.speech} method.
   * Example: `Zira`.
   */
  name: string;

  /**
   * The gender of the voice.
   * Example: `Female`.
   */
  gender: 'Male' | 'Female';

  /**
   * The language of this voice.
   * Example: `English`.
   */
  language: string;

  /**
   * A list of the supported formats that this voice can generate audio.
   * Example: `['mp3', 'wav']`.
   */
  supportedFormats: string[];

  /**
   * The voice description.
   * Example: `Zira (English - en-US)`.
   */
  description: string;

  /**
   * If this voice belongs to the standard tier.
   * Example: `true`.
   */
  isStandard: boolean;

  /**
   * If this voice belongs to the premium tier.
   * Example: `true`.
   */
  isPremium: boolean;

  /**
   * If this voice belongs to the exclusive tier.
   * Example: `true`.
   */
  isExclusive: boolean;

  /**
   * If this voice belongs to the neural voices tier.
   * Example: `true`.
   */
  isNeural: boolean;

  /**
   * If this voice can use the speech marks feature.
   * Example: `true`.
   */
  canUseSpeechMarks: boolean;

  /**
   * If this voice can use the whisper feature.
   * Example: `true`.
   */
  canWhisper: boolean;

  /**
   * If this voice can use the word break pause feature.
   * Example: `true`.
   */
  canUseWordBreak: boolean;

  /**
   * If this voice can use the softer speech feature.
   * Example: `true`.
   */
  canSpeakSoftly: boolean;

  /**
   * If this voice can use the volume setting.
   * Example: `true`.
   */
  canUseVolume: boolean;

  /**
   * If this voice can use the pitch setting.
   * Example: `true`.
   */
  canUsePitch: boolean;
};

/**
 * The raw response for the [Voice list](https://manage.talkify.net/docs#api-reference-speech-voices) API.
 * This type is used internally within the {@link Talkify.availableVoices} method.
 */
type VoiceResponse = {
  Culture: string;
  Name: string;
  Description: string;
  IsStandard: boolean;
  IsPremium: boolean;
  IsExclusive: boolean;
  IsNeural: boolean;
  CanUseSpeechMarks: boolean;
  CanWhisper: boolean;
  CanUseWordBreak: boolean;
  CanSpeakSoftly: boolean;
  CanUseVolume: boolean;
  CanUsePitch: boolean;
  SupportsSpeechMarks: boolean;
  Gender: 'Male' | 'Female';
  StandardVoice: boolean;
  SupportedFormats: string[];
  Language: string;
};

export type Language = {
  name: string;
  cultures: string[];
};

type DetectLanguageResponse = {
  SpecialCharacters: string[];
  Language: number;
  Cultures: string[];
  LanguageName: string;
};

export class Talkify {
  private defaultOptions: TalkifyOptions;
  private connector: AxiosInstance;

  constructor(options: TalkifyOptions) {
    if (!options?.key) {
      throw new TalkifyError(
        new Error('Talkify API-key not given. Visit https://manage.talkify.net to create your own API-key.'),
        'KEY_MISSING',
      );
    }

    this.validateOptions(options);

    this.defaultOptions = {
      ...options,
      key: options.key,
      format: options.format ?? 'mp3',
      ssml: options.ssml ?? true,
    };

    this.connector = axios.create({
      baseURL: 'https://talkify.net/api/',
      headers: { 'x-api-key': options.key },
    });
  }

  private validateOptions(options?: Partial<TalkifyOptions>) {
    const validFormats = ['mp3', 'wav'];
    if (options?.format && !validFormats.includes(options.format)) {
      throw new TalkifyError(
        new Error(`Invalid value for \'format\' property. Available values: ${validFormats.join(',')}`),
        'VALIDATION_ERROR',
      );
    }
    if (options?.volume && (options.volume < -10 || options.volume > 10)) {
      throw new TalkifyError(new Error("Invalid range for 'volume' property. Min: -10, Max: 10."), 'VALIDATION_ERROR');
    }
    if (options?.pitch && (options.pitch < -10 || options.pitch > 10)) {
      throw new TalkifyError(new Error("Invalid range for 'pitch' property. Min: -10, Max: 10."), 'VALIDATION_ERROR');
    }
    if (options?.wordBreak && (options.wordBreak < 0 || options.wordBreak > 1000)) {
      throw new TalkifyError(
        new Error("Invalid range for 'wordBreak' property. Min: 0, Max: 1000."),
        'VALIDATION_ERROR',
      );
    }
  }

  /**
   * This method will synthetize a text-to-speech audio with the given text string or SSML XML content.
   * 
   * **Important:** When using SSML, the text input must be correct. All XML characters that are not part of the SSML syntax must be escaped or a `Bad Request` will be thrown.
   * 
   * @param text - The text to be used for generating the TTS audio.
   * @param [options] - An optional `SpeechOptions` object that will override the default options from the Talkify instance.
   * @returns A {@link SpeechStream} object will be returned, which is a [`Readable` stream](https://nodejs.org/api/stream.html#readable-streams) that can be used for piping into processing or writing into a file.
   */
  public async speech(text: string, options?: SpeechOptions): Promise<SpeechStream> {
    this.validateOptions(options);
    try {
      let selectedVoice = options?.voice ?? this.defaultOptions.voice;
      if (typeof selectedVoice !== 'string') {
        selectedVoice = selectedVoice?.name;
      }
      let fallbackLanguage = options?.fallbackLanguage ?? this.defaultOptions.fallbackLanguage;
      fallbackLanguage = typeof fallbackLanguage === 'string' ? fallbackLanguage : fallbackLanguage?.name;
      const response = await this.connector.post<Readable>(
        'speech/v1',
        {
          Text: text,
          Format: options?.format ?? this.defaultOptions.format,
          FallbackLanguage: fallbackLanguage,
          Voice: selectedVoice,
          Rate: options?.rate ?? this.defaultOptions.rate,
          TextType: !(options?.ssml ?? this.defaultOptions.ssml) ? 0 : 1,
          Whisper: options?.whisper ?? this.defaultOptions.whisper,
          Soft: options?.soft ?? this.defaultOptions.soft,
          Volume: options?.volume ?? this.defaultOptions.volume,
          WordBreakMs: options?.wordBreak ?? this.defaultOptions.wordBreak,
          Pitch: options?.pitch ?? this.defaultOptions.pitch,
        },
        { responseType: 'stream' },
      );
      return response.data;
    } catch (_err) {
      const err = _err as AxiosError;
      throw new TalkifyError(
        err,
        'REQUEST_ERROR',
        err.response?.statusText ?? 'Could not synthetize the audio',
        err.response?.status,
      );
    }
  }

  public async availableVoices(language?: Language | string): Promise<Voice[]> {
    try {
      const response = await this.connector.get('speech/v1/voices', { params: { key: this.defaultOptions.key } });

      // Sanitize response
      const voices: Voice[] = [];
      const languageFilter = typeof language === 'string' ? language : language?.name;
      response.data.forEach((rawVoice: VoiceResponse) => {
        if (languageFilter && rawVoice.Language.toLowerCase() !== languageFilter.toLowerCase()) return;
        voices.push({
          culture: rawVoice.Culture,
          name: rawVoice.Name,
          gender: rawVoice.Gender,
          language: rawVoice.Language,
          supportedFormats: rawVoice.SupportedFormats.map((format) => format.toLowerCase()),
          description: rawVoice.Description,
          isStandard: rawVoice.IsStandard,
          isPremium: rawVoice.IsPremium,
          isExclusive: rawVoice.IsExclusive,
          isNeural: rawVoice.IsNeural,
          canUseSpeechMarks: rawVoice.CanUseSpeechMarks,
          canWhisper: rawVoice.CanWhisper,
          canUseWordBreak: rawVoice.CanUseWordBreak,
          canSpeakSoftly: rawVoice.CanSpeakSoftly,
          canUseVolume: rawVoice.CanUseVolume,
          canUsePitch: rawVoice.CanUsePitch,
        });
      });

      return voices;
    } catch (_err) {
      const err = _err as AxiosError;
      throw new TalkifyError(
        err,
        'REQUEST_ERROR',
        err.response?.statusText ?? 'Could not fetch the voices list',
        err.response?.status,
      );
    }
  }

  public async detectLanguage(text: string): Promise<Language | undefined> {
    try {
      const response = await this.connector.get<DetectLanguageResponse>('language/v1/detect', {
        params: {
          text,
          key: this.defaultOptions.key,
        },
      });

      if (response.data.Language === -1) return undefined;
      return {
        name: response.data.LanguageName,
        cultures: response.data.Cultures,
      };
    } catch (_err) {
      const err = _err as AxiosError;
      throw new TalkifyError(
        err,
        'REQUEST_ERROR',
        err.response?.statusText ?? 'Could not fetch the language detection response',
        err.response?.status,
      );
    }
  }
}

export default Talkify;
